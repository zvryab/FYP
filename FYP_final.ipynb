{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPD8R1iMr6x7yamvh7f9eOS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zvryab/FYP/blob/main/FYP_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p9F2bkpxhf_M"
      },
      "outputs": [],
      "source": [
        "!pip install langchain\n",
        "!pip install langchain-core\n",
        "!pip install langchain-community\n",
        "\n",
        "!pip install --upgrade pip setuptools wheel"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Terminal Text:\n",
        "\n",
        "/curl -fsSL https://ollama.com/install.sh | sh /ollama serve & ollama run llama2 /ollama pull llama3.1"
      ],
      "metadata": {
        "id": "GC6A0l0whqBi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.llms import Ollama\n",
        "\n",
        "llm = Ollama(\n",
        "    model=\"llama3.1\",  # or whicever model I pulled, use 3.3 for better results\n",
        "    base_url=\"https://d06d-134-151-21-61.ngrok-free.app\",\n",
        "    temperature=0,\n",
        ")\n"
      ],
      "metadata": {
        "id": "mn_QQekhhnP5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.chains import ConversationChain"
      ],
      "metadata": {
        "id": "rP4R7vwGhvo2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize memory to store conversation context\n",
        "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)"
      ],
      "metadata": {
        "id": "FONDyW56hyZ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install psycopg2 sqlalchemy langchain ollama"
      ],
      "metadata": {
        "id": "XUdbZbXhh02o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain langchain-community sqlalchemy psycopg2-binary\n",
        "\n",
        "from sqlalchemy import create_engine\n",
        "from langchain_community.llms import Ollama\n",
        "from langchain_community.agent_toolkits import create_sql_agent\n",
        "from langchain_community.utilities import SQLDatabase\n",
        "from langchain.agents.agent_types import AgentType\n",
        "\n",
        "# Step 1: Set up database engine (already working)\n",
        "DB_HOST = \"7.tcp.eu.ngrok.io\"\n",
        "DB_PORT = \"11662\"\n",
        "DB_NAME = \"sampledb\"\n",
        "DB_USER = \"postgres\"\n",
        "\n",
        "engine = create_engine(f\"postgresql://{DB_USER}@{DB_HOST}:{DB_PORT}/{DB_NAME}\")\n",
        "\n",
        "# Step 2: Set up LangChain SQLDatabase object\n",
        "db = SQLDatabase(engine)"
      ],
      "metadata": {
        "id": "uB_3vSVxh8mn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains.sql_database.prompt import PROMPT_SUFFIX, _mysql_prompt\n",
        "from langchain.chains import LLMChain"
      ],
      "metadata": {
        "id": "tJXOL8OEh_5f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Set up Ollama LLM\n",
        "llm = Ollama(model=\"llama3.1\")  # or \"mistral\", etc.\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"input\", \"table_info\"],\n",
        "    template=_mysql_prompt + PROMPT_SUFFIX,\n",
        ")\n",
        "\n",
        "llm_chain = LLMChain(llm=llm, prompt=prompt, verbose=True)\n",
        "\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "custom_sql_prompt = PromptTemplate(\n",
        "    input_variables=[\"input\", \"table_info\"],\n",
        "    template=\"\"\"\n",
        "You are an expert SQL generator designed to interact with a PostgreSQL database.\n",
        "Generate a syntactically correct SQL query to answer the given natural language question.\n",
        "\n",
        "Only output the SQL query. Do not include explanations, comments, or intermediate steps.\n",
        "\n",
        "Schema:\n",
        "{table_info}\n",
        "\n",
        "Question:\n",
        "{input}\n",
        "\n",
        "SQL Query:\n",
        "\"\"\"\n",
        ")\n",
        "\n",
        "# Step 4: Create the SQL agent\n",
        "agent_executor = create_sql_agent(\n",
        "    llm=llm,\n",
        "    db=db,\n",
        "    agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    verbose=True,\n",
        "    handle_parsing_errors=True,\n",
        "    memory=memory\n",
        "    #prefix= custom_prefix\n",
        ")\n"
      ],
      "metadata": {
        "id": "Kstrrl3JiCQb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio"
      ],
      "metadata": {
        "id": "clWNKsu3iGXW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install matplotlib plotly"
      ],
      "metadata": {
        "id": "Si7K_NAwiIne"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sqlalchemy import text\n",
        "\n",
        "def visualize_query(query):\n",
        "    try:\n",
        "        # Execute the query and load results into a DataFrame\n",
        "        with engine.connect() as conn:\n",
        "            result = conn.execute(text(query))\n",
        "            data = result.fetchall()\n",
        "            columns = result.keys()\n",
        "\n",
        "        # Create a DataFrame from the query result\n",
        "        df = pd.DataFrame(data, columns=columns)\n",
        "\n",
        "        # Basic visualization: Bar chart if there are two columns (label and value)\n",
        "        if df.shape[1] == 2:\n",
        "            plt.figure(figsize=(8, 5))\n",
        "            plt.bar(df.iloc[:, 0], df.iloc[:, 1], color='skyblue')\n",
        "            plt.title(\"Query Result Visualization\")\n",
        "            plt.xlabel(df.columns[0])\n",
        "            plt.ylabel(df.columns[1])\n",
        "            plt.xticks(rotation=45)\n",
        "            plt.tight_layout()\n",
        "\n",
        "            # Save the plot as an image\n",
        "            plt.savefig(\"query_result.png\")\n",
        "            plt.close()\n",
        "            return \"query_result.png\"\n",
        "        else:\n",
        "            return \"Visualization not supported for this query format.\"\n",
        "    except Exception as e:\n",
        "        return f\"Error in visualization: {str(e)}\"\n"
      ],
      "metadata": {
        "id": "E10ILJeKiKmo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "def sql_query_agent(input_text, output_type):\n",
        "    try:\n",
        "        # Replace with the function you already have to get SQL results\n",
        "        result = agent_executor.run(input_text)\n",
        "\n",
        "                # If the output type is \"Visualization\", generate a plot\n",
        "        if output_type == \"Graph\":\n",
        "            image_path = visualize_query(result)\n",
        "            if image_path.startswith(\"Error\"):\n",
        "                return image_path\n",
        "            return gr.Image.update(value=image_path)\n",
        "\n",
        "        return str(result)\n",
        "    except Exception as e:\n",
        "        return f\"Error: {str(e)}\"\n",
        "\n",
        "# Create the Gradio interface\n",
        "iface = gr.Interface(\n",
        "    fn=sql_query_agent,\n",
        "    inputs=[\n",
        "        gr.Textbox(label=\"SQL Query\"),\n",
        "        gr.Dropdown(choices=[\"Text\", \"Graph\"], label=\"Output Type\", value=\"Text\")\n",
        "    ],\n",
        "    outputs=gr.Textbox(label=\"Query Result\"),\n",
        "    title=\"FYP: SQL Query Agent with Visualization\",\n",
        "    description=\"Ask a question about your database, and I will generate and execute the SQL query for you. The agent remembers the context of previous questions.\",\n",
        ")\n"
      ],
      "metadata": {
        "id": "ErbBnGl3iNpL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iface.launch()"
      ],
      "metadata": {
        "id": "6v7No1NmiRyq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RVFR-1A_iTtq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}